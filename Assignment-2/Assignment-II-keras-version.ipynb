{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment - II  (Keras Version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation With RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preprocess the text data: The text data needs to be tokenized, possibly with additional steps like lowercasing and punctuation removal. You'll also need to convert the text data into sequences that your RNN can learn from. \n",
    "\n",
    "\n",
    "2. Implement an RNN: Using your chosen deep learning framework, implement an RNN, LSTM, or GRU for this task. Decide on aspects such as the number of layers, hidden units, etc.\n",
    "\n",
    "\n",
    "3. Train your model: Train the model using your processed data. Make sure to implement a mechanism to save the weights of the model periodically or when it achieves the best performance on a validation set.\n",
    "\n",
    "\n",
    "4. Generate new text: Using your trained model, generate new text that mimics the style of the training corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess the text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the reference file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 02:15:59.408057: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-26 02:16:00.508658: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-26 02:16:02.727646: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-26 02:16:08.730292: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "\n",
    "# open file path 'rb' implies read binary\n",
    "# we lower everything to make it easier to learn\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
    "\n",
    "text = text[300000:800000]\n",
    "\n",
    "# get all the unique characters in the text\n",
    "characters = sorted(set(text))\n",
    "\n",
    "# create a dictionary that maps characters to their index\n",
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "\n",
    "# Decoding dictionary that maps index to characters\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))\n",
    "\n",
    "SEQ_LENGTH = 40  # how long of a preceding sequence to collect for the RNN\n",
    "STEP_SIZE = 3  # how many characters to skip before sampling the next sequence\n",
    "\n",
    "sentences = []\n",
    "next_characters = []\n",
    "\n",
    "# loop through the text and create sequences\n",
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_characters.append(text[i + SEQ_LENGTH])\n",
    "\n",
    "# create a numpy array of zeros to store the data\n",
    "X = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=bool)\n",
    "y = np.zeros((len(sentences), len(characters)), dtype=bool)\n",
    "\n",
    "# loop through the sentences and characters and convert them to one-hot encoding\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_characters[i]]] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-25 23:37:02.219634: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 259980240 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 97ms/step - loss: 2.5059\n",
      "Epoch 2/4\n",
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 103ms/step - loss: 1.7807\n",
      "Epoch 3/4\n",
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 96ms/step - loss: 1.6087\n",
      "Epoch 4/4\n",
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 96ms/step - loss: 1.5262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7394749dba00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "\n",
    "model.fit(X, y, batch_size=256, epochs=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. RNN Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in ashes, some coal-black,\n",
      "for the depost the county the county and the soul\n",
      "would the some to the counter to the change\n",
      "that he stay the strength with the county\n",
      "the strength to the chosent to the soul word the soul\n",
      "the county the strength of the brother's fies\n",
      "the still to the still to the soul to the stines,\n",
      "and truth the some to me n\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Assuming text, SEQ_LENGTH, characters, char_to_index, and index_to_char are defined elsewhere\n",
    "\n",
    "# Function to sample an index from the model's output predictions\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds + 1e-10) / temperature  # Added epsilon to prevent log(0)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# Text generation function\n",
    "def generate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x_pred = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_to_index[char]] = 1\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_char = index_to_char[next_index]  # Corrected to map index to character\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    return generated\n",
    "\n",
    "# Example usage\n",
    "print(generate_text(300, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i am too sore enpierced with his shaft\n",
      "to mageter and mine to the sending:\n",
      "o, come the in the strengt shall brought.\n",
      "\n",
      "lady:\n",
      "i speet with his drow to love to more to go's man.\n",
      "\n",
      "benvolio:\n",
      "gaunt, truite the compart follow me to this romeo his mosted,\n",
      "and drunknt to me shall how be the soul,\n",
      "and truth hath of the boy? for him, to a very\n",
      "and \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(300, 0.6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
